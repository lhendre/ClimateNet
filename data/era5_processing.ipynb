{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25187dcc-8bd7-4c8c-8b9c-a562a84fe57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pygrib\n",
    "import netCDF4\n",
    "import scipy\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "DATA_DIR=\"/root/data_downloads\"\n",
    "era5_multi_level_dir=f\"{DATA_DIR}/era5/multi\"\n",
    "era5_single_level_dir=f\"{DATA_DIR}/era5/single\"\n",
    "%alias mkdatadir mkdir -p %l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f06fff6-175b-4785-a200-cf45f49dacf6",
   "metadata": {},
   "source": [
    "## Get get ibtracs labels for current year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb91aad9-b1c3-42b5-bc44-56eeb3a4d3ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/data_downloads/ibtracs/IBTrACS.since1980.v04r00.nc already downloaded\n"
     ]
    }
   ],
   "source": [
    "s3key = \"data/ibtracs/IBTrACS.since1980.v04r00.nc\"\n",
    "ibtracs_dir = f\"{DATA_DIR}/ibtracs\"\n",
    "\n",
    "%mkdatadir $ibtracs_dir\n",
    "# dest = \"/data_downloads/ibtracs/IBTrACS.ALL.v04r00.nc\"\n",
    "ibtracs_dest = f\"{ibtracs_dir}/IBTrACS.since1980.v04r00.nc\"\n",
    "if os.path.exists(ibtracs_dest):\n",
    "    print(f\"{ibtracs_dest} already downloaded\")\n",
    "else:\n",
    "    s3 = boto3.client('s3')\n",
    "    s3.download_file(bucket, s3key, ibtracs_dest)\n",
    "    print(f\"downloaded {ibtracs_dest}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5da30d3-a37d-4536-b038-4ff4af8f4723",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestamp_storms.pickle exists, skipping...\n"
     ]
    }
   ],
   "source": [
    "ibtracs_nc = netCDF4.Dataset(ibtracs_dest)\n",
    "\"\"\"\n",
    "Need to combine the datasets by hour.  Will want to OR the storms together where they share hours \n",
    "to produce a global mask of TC labels.  This will then be included in the outputted netcdf files.\n",
    "\"\"\"\n",
    "def ibtracs_time_to_pd_timestamp(ibtracs_time):\n",
    "    ts = pd.to_datetime(ibtracs_time)\n",
    "    return ts\n",
    "\n",
    "\n",
    "ibtracs_roci = ibtracs_nc.variables[\"bom_roci\"]\n",
    "start_year = 2018\n",
    "end_year = 2018\n",
    "timestamp_storms = {}\n",
    "print_freq = 100\n",
    "\n",
    "if os.path.exists(\"timestamp_storms.pickle\"):\n",
    "    with open(\"timestamp_storms.pickle\", \"rb\") as file:\n",
    "        print(\"timestamp_storms.pickle exists, skipping...\") \n",
    "        timestamp_storms = pickle.load(file)\n",
    "else:\n",
    "    for storm_idx, storm_times in enumerate(ibtracs_nc.variables[\"iso_time\"][:]):\n",
    "        for time_idx, time in enumerate(storm_times):\n",
    "            timestamp_str = time.tobytes().decode(\"utf-8\")\n",
    "            if not timestamp_str:\n",
    "                break # we have hit the last timestamp for the storm\n",
    "            # Convert byte arrays to pandas Timestamp\n",
    "            timestamp = ibtracs_time_to_pd_timestamp(timestamp_str) # \n",
    "            if start_year <= timestamp.year <= end_year:\n",
    "                storm_tup = (storm_idx, time_idx)\n",
    "                if timestamp_str in timestamp_storms:\n",
    "                    timestamp_storms[timestamp_str].append(storm_tup)\n",
    "                else:\n",
    "                    timestamp_storms[timestamp_str] = [storm_tup]\n",
    "        if storm_idx % print_freq == 0:\n",
    "            print(f\"{storm_idx} of {ibtracs_nc.variables['iso_time'].shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf487253-e43f-48a1-8e69-eebeccb43055",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storms found at 2759 timestamps in the 2018-2018 year range\n"
     ]
    }
   ],
   "source": [
    "print(f\"Storms found at {len(timestamp_storms)} timestamps in the {start_year}-{end_year} year range\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04567ae-ea00-4033-8e40-4c5880728f17",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Process ERA5 data and output augmented netcdf file for each day\n",
    "Note: time in this dataset has units: hours since 1900-01-01 00:00:00.0\n",
    "can be converted to a pandas timestamp with\n",
    "```\n",
    "pd.to_datetime(timestamp, unit='h', origin='1900-01-01 00:00:00.0')\n",
    "```\n",
    "and can do the reverse conversion via\n",
    "```\n",
    "origin = pd.Timestamp('1900-01-01 00:00:00')\n",
    "hours_since_1900 = int((pandas_timestamp - origin).total_seconds() / 3600)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98da4dda-de17-4718-b1c6-65d1c06db1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = \"2018\"\n",
    "month = \"01\"\n",
    "day = \"01\"\n",
    "# filename=f'{era5_single_level_dir}/{year}-{month}-{day}.grib'\n",
    "single_file=f'{era5_single_level_dir}/{year}-{month}-{day}.nc'\n",
    "multi_file=f'{era5_multi_level_dir}/{year}-{month}-{day}.nc'\n",
    "\n",
    "single_nc =  netCDF4.Dataset(single_file)\n",
    "multi_nc =  netCDF4.Dataset(multi_file)\n",
    "single_vars = single_nc.variables.keys()\n",
    "multi_vars = multi_nc.variables.keys()\n",
    "\n",
    "\n",
    "# mtpr = xr.DataArray(single_nc.variables[\"mtpr\"], coords={\n",
    "#     'time': single_nc.variables[\"time\"][:],\n",
    "#     'lat': single_nc.variables[\"latitude\"][:], \n",
    "#     'lon': single_nc.variables[\"longitude\"][:]}, \n",
    "#     dims=('time','lat', 'lon'))\n",
    "\n",
    "# sp = xr.DataArray(single_nc.variables[\"sp\"], coords={\n",
    "#     'time': single_nc.variables[\"time\"][:],\n",
    "#     'lat': single_nc.variables[\"latitude\"][:], \n",
    "#     'lon': single_nc.variables[\"longitude\"][:]}, \n",
    "#     dims=('time','lat', 'lon'))\n",
    "\n",
    "# tcwv = xr.DataArray(single_nc.variables[\"tcwv\"], coords={\n",
    "#     'time': single_nc.variables[\"time\"][:],\n",
    "#     'lat': single_nc.variables[\"latitude\"][:], \n",
    "#     'lon': single_nc.variables[\"longitude\"][:]}, \n",
    "#     dims=('time','lat', 'lon'))\n",
    "\n",
    "# pv850 = xr.DataArray(multi_nc.variables[\"pv\"], coords={\n",
    "#     'time': multi_nc.variables[\"time\"][:],\n",
    "#     'lat': multi_nc.variables[\"latitude\"][:], \n",
    "#     'lon': multi_nc.variables[\"longitude\"][:]}, \n",
    "#     dims=('time','lat', 'lon'))\n",
    "\n",
    "# u850 = xr.DataArray(multi_nc.variables[\"u\"], coords={\n",
    "#     'time': multi_nc.variables[\"time\"][:],\n",
    "#     'lat': multi_nc.variables[\"latitude\"][:], \n",
    "#     'lon': multi_nc.variables[\"longitude\"][:]}, \n",
    "#     dims=('time','lat', 'lon'))\n",
    "\n",
    "# v850 = xr.DataArray(multi_nc.variables[\"v\"], coords={\n",
    "#     'time': multi_nc.variables[\"time\"][:],\n",
    "#     'lat': multi_nc.variables[\"latitude\"][:], \n",
    "#     'lon': multi_nc.variables[\"longitude\"][:]}, \n",
    "#     dims=('time','lat', 'lon'))\n",
    "\n",
    "# ws850 = (u850**2 + v850**2)**0.5\n",
    "# print(v850, ws850)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a53fca0-b0bc-44b4-9ca7-ab7670acbd1e",
   "metadata": {},
   "source": [
    "## Compute labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e7ed4c3-53f3-4021-8223-1ea20be77ffd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 of 2759\n",
      "Writing dataset to /root/data_downloads/era5_labeled/2018-12-13.nc\n",
      "\"not all values found in index 'time'. Try setting the `method` keyword argument (example: method='nearest').\"\n",
      "failed on timestamp 2018-12-14 17:00:00\n",
      "Writing dataset to /root/data_downloads/era5_labeled/2018-12-14.nc\n",
      "100 of 2759\n",
      "Writing dataset to /root/data_downloads/era5_labeled/2018-12-15.nc\n",
      "Writing dataset to /root/data_downloads/era5_labeled/2018-12-28.nc\n",
      "Writing dataset to /root/data_downloads/era5_labeled/2018-12-30.nc\n",
      "Writing dataset to /root/data_downloads/era5_labeled/2018-12-31.nc\n",
      "Labeled a total of 48 timesteps\n"
     ]
    }
   ],
   "source": [
    "def haversine_distance(lat, lon, lat_center, lon_center):\n",
    "    \"\"\"\n",
    "    returns matrix of dim (lat,lon) with distance in nautical miles\n",
    "    \"\"\"\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat, lon, lat_center, lon_center])\n",
    "    # Haversine formula\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = np.sin(dlat[:,None] / 2) ** 2 + np.cos(lat1[:,None]) * np.cos(lat2) * np.sin(dlon[None,:] / 2) ** 2\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    r = 6371  # Radius of the Earth in kilometers\n",
    "\n",
    "    # Calculate the distance in \n",
    "    distance = c * r\n",
    "    # 1.852 km per nautical mile\n",
    "    return distance / 1.852\n",
    "\n",
    "\n",
    "def make_labeled_dataset(pd_timestamp, timestep_labels)->None:\n",
    "    \"\"\"\n",
    "    Take a timestamp and the labels for the timestamp, combine with\n",
    "    ERA5 data, regrid, and return an xarray Dataset.  These datasets\n",
    "    can later be concatenated along the time dimension before being \n",
    "    written to a file.\n",
    "    \n",
    "    We try to match the format of the climatenet augmented dataset.\n",
    "    The ClimateDatasetLabeled class concatenates files across the \n",
    "    time dimension, so we can put as many timesteps as we want in \n",
    "    each file. Here we take the timestep and find the matching \n",
    "    ERA5 file and extract the variables for the corresponding timestamp.\n",
    "    \n",
    "    \n",
    "    Only some variables are provided here.  If more are desired, they\n",
    "    can be additionally downloaded from copernicus. \n",
    "    \n",
    "    Augmented climatenet dataset:\n",
    "    dimensions(sizes): lat(768), lon(1152), time(1)\n",
    "    variables(dimensions): float64 lat(lat), float64 lon(lon), \n",
    "        float32 TMQ(time, lat, lon), float32 U850(time, lat, lon), \n",
    "        float32 V850(time, lat, lon), float32 UBOT(time, lat, lon), \n",
    "        float32 VBOT(time, lat, lon), float32 QREFHT(time, lat, lon), \n",
    "        float32 PS(time, lat, lon), float32 PSL(time, lat, lon), \n",
    "        float32 T200(time, lat, lon), float32 T500(time, lat, lon), \n",
    "        float32 PRECT(time, lat, lon), float32 TS(time, lat, lon), \n",
    "        float32 TREFHT(time, lat, lon), float32 Z1000(time, lat, lon), \n",
    "        float32 Z200(time, lat, lon), float32 ZBOT(time, lat, lon), \n",
    "        <class 'str'> time(time), int64 LABELS(lat, lon)\n",
    "    \"\"\"\n",
    "    origin = pd.Timestamp('1900-01-01 00:00:00')\n",
    "    hours_since_1900 = int((pd_timestamp - origin).total_seconds() / 3600)\n",
    "    year = pd_timestamp.year\n",
    "    month = pd_timestamp.strftime('%m')\n",
    "    day = pd_timestamp.strftime('%d')\n",
    "    # filename=f'{era5_single_level_dir}/{year}-{month}-{day}.grib'\n",
    "    single_file=f'{era5_single_level_dir}/{year}-{month}-{day}.nc'\n",
    "    multi_file=f'{era5_multi_level_dir}/{year}-{month}-{day}.nc'\n",
    "\n",
    "    single_nc =  netCDF4.Dataset(single_file)\n",
    "    multi_nc =  netCDF4.Dataset(multi_file)\n",
    "    single_vars = single_nc.variables.keys()\n",
    "    multi_vars = multi_nc.variables.keys()\n",
    "\n",
    "\n",
    "    mtpr = xr.DataArray(single_nc.variables[\"mtpr\"], name=\"PRECT\", coords={\n",
    "        'time': single_nc.variables[\"time\"][:],\n",
    "        'lat': single_nc.variables[\"latitude\"][:], \n",
    "        'lon': single_nc.variables[\"longitude\"][:]}, \n",
    "        dims=('time','lat', 'lon')).sel(time=hours_since_1900)\n",
    "\n",
    "    sp = xr.DataArray(single_nc.variables[\"sp\"], name=\"PSL\", coords={\n",
    "        'time': single_nc.variables[\"time\"][:],\n",
    "        'lat': single_nc.variables[\"latitude\"][:], \n",
    "        'lon': single_nc.variables[\"longitude\"][:]}, \n",
    "        dims=('time','lat', 'lon')).sel(time=hours_since_1900)\n",
    "\n",
    "    tcwv = xr.DataArray(single_nc.variables[\"tcwv\"], name=\"TMQ\", coords={\n",
    "        'time': single_nc.variables[\"time\"][:],\n",
    "        'lat': single_nc.variables[\"latitude\"][:], \n",
    "        'lon': single_nc.variables[\"longitude\"][:]}, \n",
    "        dims=('time','lat', 'lon')).sel(time=hours_since_1900)\n",
    "\n",
    "    pv850 = xr.DataArray(multi_nc.variables[\"pv\"], name=\"VRT850\", coords={\n",
    "        'time': multi_nc.variables[\"time\"][:],\n",
    "        'lat': multi_nc.variables[\"latitude\"][:], \n",
    "        'lon': multi_nc.variables[\"longitude\"][:]}, \n",
    "        dims=('time','lat', 'lon')).sel(time=hours_since_1900)\n",
    "\n",
    "    u850 = xr.DataArray(multi_nc.variables[\"u\"], name=\"U850\", coords={\n",
    "        'time': multi_nc.variables[\"time\"][:],\n",
    "        'lat': multi_nc.variables[\"latitude\"][:], \n",
    "        'lon': multi_nc.variables[\"longitude\"][:]}, \n",
    "        dims=('time','lat', 'lon')).sel(time=hours_since_1900)\n",
    "\n",
    "    v850 = xr.DataArray(multi_nc.variables[\"v\"], name=\"V850\", coords={\n",
    "        'time': multi_nc.variables[\"time\"][:],\n",
    "        'lat': multi_nc.variables[\"latitude\"][:], \n",
    "        'lon': multi_nc.variables[\"longitude\"][:]}, \n",
    "        dims=('time','lat', 'lon')).sel(time=hours_since_1900)\n",
    "\n",
    "    ws850 = ((u850**2 + v850**2)**0.5).rename(\"WS850\")\n",
    "    \n",
    "    labels = xr.DataArray(timestep_labels[None,:,:], name=\"LABELS\", coords={\n",
    "        'time': np.array([hours_since_1900]),\n",
    "        'lat': multi_nc.variables[\"latitude\"][:], \n",
    "        'lon': multi_nc.variables[\"longitude\"][:]},\n",
    "        dims=('time','lat', 'lon'))\n",
    "    \n",
    "\n",
    "    dataset = xr.Dataset(\n",
    "        data_vars={\n",
    "            \"PRECT\": mtpr,\n",
    "            \"PSL\": sp,\n",
    "            \"TMQ\": tcwv,\n",
    "            \"VRT850\": pv850,\n",
    "            \"WS850\": ws850,\n",
    "            \"LABELS\": labels\n",
    "        },\n",
    "        # coords={\n",
    "        #     'time': \n",
    "        # }\n",
    "    )\n",
    "    single_nc.close()\n",
    "    multi_nc.close()\n",
    "    return dataset\n",
    "\n",
    "# max_roci = np.argmax(ibtracs_nc.variables[\"bom_roci\"])\n",
    "# max_roci = np.unravel_index(max_roci, ibtracs_nc.variables[\"bom_roci\"].shape)\n",
    "# print(\"roci max\", np.max(ibtracs.variables[\"bom_roci\"]), max_roci)\n",
    "\n",
    "\n",
    "# need to treat fill values as none or numpy gets unhappy\n",
    "masked_lat = ibtracs_nc.variables[\"lat\"][:]\n",
    "masked_lat = np.ma.masked_array(masked_lat, mask=(masked_lat == ibtracs_nc.variables[\"lat\"]._FillValue), fill_value=None)\n",
    "masked_lon = ibtracs_nc.variables[\"lon\"][:]\n",
    "masked_lon = np.ma.masked_array(masked_lon, mask=(masked_lon == ibtracs_nc.variables[\"lon\"]._FillValue), fill_value=None)\n",
    "masked_roci = ibtracs_nc.variables[\"bom_roci\"][:]\n",
    "masked_roci = np.ma.masked_array(masked_roci, mask=(masked_roci == ibtracs_nc.variables[\"bom_roci\"]._FillValue), fill_value=None)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "TIMESTEPS_PER_FILE=8\n",
    "unwritten_timestamps = 0\n",
    "files_written = 0\n",
    "start_timestamp = None\n",
    "file_dataset = None\n",
    "total_labeled = 0\n",
    "print_freq = 100\n",
    "iteration = 0\n",
    "LABEL_DIR = f\"{DATA_DIR}/era5_labeled\"\n",
    "completed_timestamps = set()\n",
    "# if os.path.exists(\"completed_timestamps.pickle\"):\n",
    "#     with open(\"completed_timestamps.pickle\", \"rb\") as file:\n",
    "#         completed_timestamps = pickle.load(file)\n",
    "#         print(f\"Remembered completed timestamps: {completed_timestamps}\")\n",
    "queued_timestamps = set()\n",
    "%mkdatadir $LABEL_DIR\n",
    "for timestamp, storms in timestamp_storms.items():\n",
    "    queued_timestamps.add(timestamp)\n",
    "    # if timestamp in completed_timestamps:\n",
    "    #     print(f\"Already completed {timestamp}, skipping...\")\n",
    "    pd_timestamp = pd.to_datetime(timestamp)\n",
    "    # if pd_timestamp < pd.Timestamp(\"2018-12-13\"):\n",
    "    #     continue\n",
    "    if start_timestamp is None:\n",
    "        start_timestamp = pd_timestamp\n",
    "    timestep_labels = np.zeros((single_nc.dimensions[\"latitude\"].size, single_nc.dimensions[\"longitude\"].size), dtype=np.int8)\n",
    "    for storm_id,timestep in storms:\n",
    "        \n",
    "\n",
    "        \n",
    "        distances = haversine_distance(\n",
    "            single_nc.variables[\"latitude\"], # pull out the time  \n",
    "            single_nc.variables[\"longitude\"], \n",
    "            masked_lat[storm_id,timestep], \n",
    "            masked_lon[storm_id,timestep]\n",
    "        )\n",
    "        storm_labels = np.where(distances <= masked_roci[storm_id,timestep], 1, 0)\n",
    "        timestep_labels = timestep_labels | storm_labels\n",
    "    if iteration % print_freq == 0:\n",
    "        print(f\"{iteration} of {len(timestamp_storms)}\")\n",
    "    iteration += 1\n",
    "    if np.max(timestep_labels) != 0:\n",
    "        try:\n",
    "            dataset = make_labeled_dataset(pd_timestamp, timestep_labels)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(f\"failed on timestamp {pd_timestamp}\")\n",
    "            continue\n",
    "        unwritten_timestamps += 1\n",
    "        total_labeled += 1\n",
    "        if file_dataset is None:\n",
    "            file_dataset = dataset\n",
    "        else:\n",
    "            file_dataset = xr.concat([file_dataset, dataset], dim='time')\n",
    "            dataset.close()\n",
    "            dataset = None\n",
    "        if unwritten_timestamps == TIMESTEPS_PER_FILE:\n",
    "            year = start_timestamp.year\n",
    "            month = start_timestamp.strftime('%m')\n",
    "            day = start_timestamp.strftime('%d')\n",
    "            dest = f\"{LABEL_DIR}/{year}-{month}-{day}.nc\"\n",
    "            print(f\"Writing dataset to {dest}\")\n",
    "            file_dataset.to_netcdf(dest, format=\"NETCDF4\")\n",
    "            file_dataset.close()\n",
    "            file_dataset = None\n",
    "            start_timestamp = None\n",
    "            unwritten_timestamps = 0\n",
    "            completed_timestamps.update(queued_timestamps)\n",
    "            queued_timestamps = set()\n",
    "            with open(\"completed_timestamps.pickle\", \"wb\") as file:\n",
    "                pickle.dump(completed_timestamps, file)\n",
    "    \n",
    "if unwritten_timestamps != 0:\n",
    "    year = start_timestamp.year\n",
    "    month = start_timestamp.strftime('%m')\n",
    "    day = start_timestamp.strftime('%d')\n",
    "    dest = f\"{LABEL_DIR}/{year}-{month}-{day}.nc\"\n",
    "    print(f\"Writing final dataset to {dest}\")\n",
    "    file_dataset.to_netcdf(dest, format=\"NETCDF4\")\n",
    "    file_dataset.close()\n",
    "    file_dataset = None\n",
    "    start_timestamp = None\n",
    "    unwritten_timestamps = 0\n",
    "    # print(np.max(timestep_labels))\n",
    "print(f\"Labeled a total of {total_labeled} timesteps\")\n",
    "# # storm_id = 2403\n",
    "# timestep = 5\n",
    "\n",
    "# distances = haversine_distance(era5_single.variables[\"latitude\"], era5_single.variables[\"longitude\"], masked_lat[storm_id,timestep], masked_lon[storm_id,timestep])\n",
    "\n",
    "# # print(distances.shape) \n",
    "# tc_label = np.where(distances <= masked_roci[storm_id,timestep], 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e76a2b2a-a725-47fb-9e5d-e46dd56da452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-13 00:00:00\n",
      "Variable                       Type              Data/Info\n",
      "----------------------------------------------------------\n",
      "DATA_DIR                       str               /root/data_downloads\n",
      "LABEL_DIR                      str               /root/data_downloads/era5_labeled\n",
      "TIMESTEPS_PER_FILE             int               8\n",
      "completed_timestamps           set               {'2018-08-29 15:00:00', '<...>', '2018-11-10 21:00:00'}\n",
      "dataset                        Dataset           <xarray.Dataset>\\nDimensi<...>0 ... 0 0 0 0 0 0 0 0 0 0\n",
      "day                            str               13\n",
      "dest                           str               /root/data_downloads/era5_labeled/2018-12-13.nc\n",
      "distances                      ndarray           721x1440: 1038240 elems, type `float32`, 4152960 bytes (3.9605712890625 Mb)\n",
      "end_year                       int               2018\n",
      "era5_multi_level_dir           str               /root/data_downloads/era5/multi\n",
      "era5_single_level_dir          str               /root/data_downloads/era5/single\n",
      "file                           BufferedWriter    <_io.BufferedWriter name=<...>leted_timestamps.pickle'>\n",
      "file_dataset                   Dataset           <xarray.Dataset>\\nDimensi<...>0 ... 0 0 0 0 0 0 0 0 0 0\n",
      "files_written                  int               0\n",
      "haversine_distance             function          <function haversine_distance at 0x7f964adebeb0>\n",
      "ibtracs_dest                   str               /root/data_downloads/ibtr<...>TrACS.since1980.v04r00.nc\n",
      "ibtracs_dir                    str               /root/data_downloads/ibtracs\n",
      "ibtracs_nc                     Dataset           <class 'netCDF4._netCDF4.<...> date_time)\\n    groups: \n",
      "ibtracs_roci                   Variable          <class 'netCDF4._netCDF4.<...>= (4687, 360)\\nfilling on\n",
      "ibtracs_time_to_pd_timestamp   function          <function ibtracs_time_to<...>estamp at 0x7f968d1736d0>\n",
      "iteration                      int               2620\n",
      "make_labeled_dataset           function          <function make_labeled_dataset at 0x7f964df36a70>\n",
      "masked_lat                     MaskedArray       [[-12.5 -12.1927366256713<...>3324279785 ... -- -- --]]\n",
      "masked_lon                     MaskedArray       [[172.5 172.4414825439453<...>9969482422 ... -- -- --]]\n",
      "masked_roci                    MaskedArray       [[-- -- -- ... -- -- --]\\<...> [-- -- -- ... -- -- --]]\n",
      "month                          str               12\n",
      "multi_file                     str               /root/data_downloads/era5/multi/2018-01-01.nc\n",
      "multi_nc                       Dataset           <class 'netCDF4._netCDF4.<...> longitude)\\n    groups: \n",
      "multi_vars                     dict_keys         dict_keys(['longitude', '<...> 'time', 'pv', 'u', 'v'])\n",
      "netCDF4                        module            <module 'netCDF4' from '/<...>ges/netCDF4/__init__.py'>\n",
      "np                             module            <module 'numpy' from '/op<...>kages/numpy/__init__.py'>\n",
      "os                             module            <module 'os' from '/opt/c<...>a5/lib/python3.10/os.py'>\n",
      "pd                             module            <module 'pandas' from '/o<...>ages/pandas/__init__.py'>\n",
      "pd_timestamp                   Timestamp         2018-12-14 17:00:00\n",
      "pickle                         module            <module 'pickle' from '/o<...>ib/python3.10/pickle.py'>\n",
      "plt                            module            <module 'matplotlib.pyplo<...>es/matplotlib/pyplot.py'>\n",
      "print_freq                     int               100\n",
      "pygrib                         module            <module 'pygrib' from '/o<...>ages/pygrib/__init__.py'>\n",
      "queued_timestamps              set               {'2018-12-14 17:00:00', '2018-12-14 15:00:00'}\n",
      "s3key                          str               data/ibtracs/IBTrACS.since1980.v04r00.nc\n",
      "scipy                          module            <module 'scipy' from '/op<...>kages/scipy/__init__.py'>\n",
      "single_file                    str               /root/data_downloads/era5/single/2018-01-01.nc\n",
      "single_nc                      Dataset           <class 'netCDF4._netCDF4.<...> longitude)\\n    groups: \n",
      "single_vars                    dict_keys         dict_keys(['longitude', '<...>', 'mtpr', 'sp', 'tcwv'])\n",
      "start_timestamp                Timestamp         2018-12-14 15:00:00\n",
      "start_year                     int               2018\n",
      "storm_id                       int               4221\n",
      "storm_labels                   ndarray           721x1440: 1038240 elems, type `int64`, 8305920 bytes (7.921142578125 Mb)\n",
      "storms                         list              n=1\n",
      "timestamp                      str               2018-12-14 17:00:00\n",
      "timestamp_storms               dict              n=2759\n",
      "timestep                       int               119\n",
      "timestep_labels                ndarray           721x1440: 1038240 elems, type `int64`, 8305920 bytes (7.921142578125 Mb)\n",
      "total_labeled                  int               369\n",
      "unwritten_timestamps           int               1\n",
      "xr                             module            <module 'xarray' from '/o<...>ages/xarray/__init__.py'>\n",
      "year                           int               2018\n"
     ]
    }
   ],
   "source": [
    "print(pd.Timestamp(\"2018-12-13\"))\n",
    "%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc52be06-bff2-44f3-96f8-20323004b006",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# tcwv.isel(time=0).plot.contourf()\n",
    "# plt.show()\n",
    "# pv850.isel(time=0).plot.contourf()\n",
    "# plt.show()\n",
    "# mtpr.isel(time=0).plot.contourf()\n",
    "# plt.show()\n",
    "# ws850.isel(time=0).plot.contourf()\n",
    "# plt.show()\n",
    "# # plt.colorbar()\n"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.m5.large",
  "kernelspec": {
   "display_name": "Python [conda env:era5] (arn:aws:sagemaker:us-west-2:236514542706:image/sagemaker-data-science-310-v1)",
   "language": "python",
   "name": "conda-env-era5-py__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
